1. 操作系统的基本特征

   1. 并发

      并发是指宏观上在一段时间内能同时运行多个程序，操作系统通过引入进程和线程，使得程序能够并发运行

   2. 共享

      1. 共享是指系统中的资源可以被多个并发进程共同使用
      2. 有两种共享方式：互斥共享和同时共享。

   3. 虚拟

      1. 虚拟技术把一个物理实体转换为多个逻辑实体
      2. 虚机技术有两种：时分复用技术和空分复用技术，
         1. 时分复用：多个金宠能在同一个处理器上并发执行使用了时分复用技术。
         2. 虚拟内存使用了空分复用技术，他将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在内存中，当使用到一个没有物理内存的页时，执行页面置换算法，将该页置换到内存中。

   4. 异步。

2. 操作系统基本功能

   1. 进程管理
      1. 进程控制、进程同步、进程通信、死锁处理、处理机调度
   2. 内存管理
      1. 内存分配，地址映射，内存保护与共享、虚拟内存等。
   3. 文件管理
      1. 文件存储空间管理、目录管理、文件读写管理和保护
   4. 设备管理
      1. 完成用户的I/O请求，方便用户使用各种设备，并提高设备的利用率
      2. 主要包括缓冲管理。设备分配、设备处理、虚拟设备等。

3. 什么是内核态，用户态，为什么要有内核态和用户态。什么是系统调用?、

   1. 在CPU的所有指令中，有一些指令是非常危险的，如果错用，将导致整个系统崩溃，所以CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通的应用程序只能使用那些不会造成灾难的指令

   2. 一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行

   3. 当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。

   4. 如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，有操作系统代为完成

      ![img](tGPV0.png)

4. 用户态到内核态的转换方式有哪些

   1. 系统调用

      1. 这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。

   2. 异常

      1. 当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

   3. 外围设备中断

      1. 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

   4. 用户态到内核态的具体切换过程

      1. 从触发方式上看，可以认为存在前述3种不同的类型，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一致的，没有任何区别，都相当于执行了一个中断响应的过程，因为系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本上也是一致的，关于它们的具体区别这里不再赘述。关于中断处理机制的细节和步骤这里也不做过多分析，涉及到由用户态切换到内核态的步骤主要包括：

         [1] 从当前进程的描述符中提取其内核栈的ss0（存放栈的段地址）及esp0（栈指针，用于指向栈的栈顶）信息。

         [2] 使用ss0和esp0指向的内核栈将当前进程的cs,eip,eflags,ss,esp信息保存起来，这个过程也完成了由用户栈到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。

         [3] 将先前由中断向量检索得到的中断处理程序的cs（代码段寄存器）,eip（存储着我们cpu要读取指令的地址）信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。

5. Linux的系统调用主要有哪些？

| Task     | Commands                    |
| -------- | --------------------------- |
| 进程控制 | fork(); exit(); wait();     |
| 进程通信 | pipe(); shmget(); mmap();   |
| 文件操作 | open(); read(); write();    |
| 设备操作 | ioctl(); read(); write();   |
| 信息维护 | getpid(); alarm(); sleep(); |
| 安全     | chmod(); umask(); chown();  |

5. 大内核和微内核的区别

   1. 大内核

      1. 大内核是将操作系统功能作为一个紧密结合的整体放到内核。

         由于各模块共享信息，因此有很高的性能。

   2. 微内核

      1. 在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。
      2. 因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。

6. 什么是中断，什么时候会使用中断，中断你的分类？

   1. 计算机处于执行期间
   2. 系统内发生了非寻常或非预期的急需处理事件
   3. CPU暂时中断当前正在执行的程序而转去执行相应的事件处理程序
   4. 处理完毕后返回原来被中断处继续执行

7. 什么是中断？中断的作用

   早期的CPU处理外设的事件(比如接收键盘输入)，往往采用“轮询”的方式。这种方式使CPU的执行效率很低，且CPU与外设不能同时工作（因为要等待CPU来“巡查”）。

    中断模式时就是说CPU不主动访问这些设备，只管处理自己的任务。如果有设备要与CPU联系，或要CPU处理一些事情，它会给CPU发一个中断请求信号。这时CPU就会放下正在进行的工作而去处理这个外设的请求。处理完中断后，CPU返回去继续执行中断以前的工作。

8. 中断的分类

   ​	从不同的角度来说，中断可以有三种分类方法。

   ​	中断可以分为同步中断（synchronous）和异步中断(asynchronous)。

   ​	中断可分为硬中断和软中断。

   ​	中断可分为可屏蔽中断（Maskable interrupt）和非屏蔽中断（Nomaskable interrupt）

   ​		

9. 进程和线程的区别

   1.  拥有资源

      进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。

   2. 调度

      线程是独立调度的基本单位。

   3. 系统开销

      由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

   4. 通信方面

   ​	线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

10. 协程是什么，与线程有什么区别

    ​	**协程是一种用户态的轻量级线程，**协程的调度完全由用户控制，在协程切换时不用使用系统调用在操作系统级别去切换，所以协程更轻量。

    1. 协程与线程最主要的区别是：线程的切换涉及到系统调用，导致内核态与用户态的切换。而协程在用户态有自己的调度器，切换时不需要操作系统级别的切换。
    2. golang对协程进行了进一步优化
       1. goroutine进一步做了优化
          1. 每个goroutine默认占用内存为2kb， 线程是8mb
          2. gouroutine在切换时只需要修改少量的寄存器的值，而线程的切换设计到模式切换(用户态到内核态)以及更多寄存器的修改。

11. 进程调度算法

    1. 批处理系统

       1. 先来先服务
       2. 短作业优先
       3. 最短剩余时间

    2. 交互式系统

       交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

       1. 时间片轮转

          将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

       2. 优先级调度

          1. 为每个进程分配一个优先级，按优先级进行调度。

             为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

       3. 多级反馈队列

          1. 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。

             多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

             每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

             可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

12. 进程同步的方式有哪些

    1. 临界区

       1. 对临界资源进行访问的那段代码称为临界区。

          为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

          ```
          // entry section
          // critical section;
          // exit section
          ```

       2. 同步与互斥

          - 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
          - 互斥：多个进程在同一时刻只有一个进程能进入临界区。

       3. 信号量

          为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数=1就是互斥量了。

          信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

          - **down** : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
          - **up** ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

       4. 管程(monitor)

          1. 管程是编程语言提供的一种抽象数据结构，用于多线程互斥访问共享资源。首先，**是互斥访问，即任一时刻只有一个线程在执行管程代码**；第二，**正在管程内的线程可以放弃对管程的控制权**，
          2. java 的wait和notify就是管程类型的

13. 进程同步和进程通信的区别

    1. 进程同步与进程通信很容易混淆，它们的区别在于：

       - 进程同步：控制多个进程按一定顺序执行；
       - 进程通信：进程间传输信息。

       进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

14. 进程通信的方式有哪些？

    1. 管道

       1. **匿名管道( pipe )：**管道是一种半双工的通信方式，数据只能**单向流动**，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指**父子进程关系**。

    2. FIFO

    3. 消息队列

       1. 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
       2. 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
       3. 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收

    4. 信号量

    5. 共享存储

       1. 允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

          需要使用信号量用来同步对共享存储的访问。

          多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

    6. 套接字

       1. 与其它通信机制不同的是，它可用于不同机器间的进程通信。

15. 锁的分类，以及各种锁的使用场景，在语言中的实现

    1. 公平锁/非公平锁

       1. 公平锁是指多个线程按照申请锁的顺序来获取锁。非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。
       2. 对于Java `ReentrantLock`而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。
       3. 对于`Synchronized`而言，也是一种非公平锁。

    2. 互斥锁和读写锁

       1. 互斥锁：ReentrantLock , Synchronized
       2. 读写锁：RenentrantReadWriteLock

    3. 乐观锁和悲观锁

       1. 悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。java中使用的各种锁都是悲观锁
       2. 乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的。
       3. 乐观锁在java中的使用，是无锁编程，常常采用CAS算法

    4. 分段锁

    5. 偏向锁/轻量级锁/重量级锁

       1. 这三种锁是指锁的状态，并且是针对`Synchronized`。在Java 5通过引入锁升级的机制来实现高效`Synchronized`。这三种锁的状态是通过对象监视器在对象头中的字段来表明的。
          偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。
          轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。
          重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。

    6. 分拆锁， 分离锁

       1. **分拆锁(lock spliting)**就是若原先的程序中多处逻辑都采用同一个锁，但各个逻辑之间又相互独立，就可以拆(Spliting)为使用多个锁，每个锁守护不同的逻辑。
          分拆锁有时候可以被扩展，分成可大可小加锁块的集合，并且它们归属于相互独立的对象，这样的情况就是**分离锁(lock striping)**。

    7. 自旋锁

       1. 在Java中，自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。

       2. ```java
          public class SpinLock {
          
            private AtomicReference<Thread> sign =new AtomicReference<>();
          
            public void lock(){
              Thread current = Thread.currentThread();
              while(!sign .compareAndSet(null, current)){
              }
            }
          
            public void unlock (){
              Thread current = Thread.currentThread();
              sign .compareAndSet(current, null);
            }
          }
          ```

          使用了CAS原子操作，lock函数将owner设置为当前线程，并且预测原来的值为空。unlock函数将owner设置为null，并且预测值为当前线程。

          当有第二个线程调用lock操作时由于owner值不为空，导致循环一直被执行，直至第一个线程调用unlock函数将owner设置为null，第二个线程才能进入临界区。

    8. 可重入锁

       1. 可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。

16. 死锁的必要条件？

    1. 互斥
    2. 占有和等待
    3. 不可抢占
    4. 环路等待

17. 死锁的处理方式

    1. 鸵鸟策略
    2. 死锁检测与死锁恢复
       1. 每种类型一个资源的死锁检测
          1. 上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。如何出现环，则有死锁
       2. 每种类型多个资源的死锁检测
    3. 死锁恢复
       1. 利用抢占恢复
       2. 利用回滚恢复
       3. 通过杀死进程恢复
    4. 死锁预防
       1. 破坏互斥条件
          1. 即允许进程同时访问某些资源。但是，有的资源是不允许被同时访问的，像打印机等等，这是由资源本身的属性所决定的。所以，这种办法并无实用价值。
       2. 破坏占有和等待条件
          1. 可以实行资源预先分配策略。即进程在运行前一次性地向系统申请它所需要的全部资源。
       3. 破坏不可抢占条件
       4. 破坏循环等待
          1. **实行资源有序分配策略**
    5. 死锁避免
       1. **银行家算法**

14. 什么是虚拟内存

    1. 虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

       为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

       从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。

       [![img](https://github.com/CyC2018/CS-Notes/raw/master/notes/pics/7b281b1e-0595-402b-ae35-8c91084c33c1.png)](https://github.com/CyC2018/CS-Notes/blob/master/notes/pics/7b281b1e-0595-402b-ae35-8c91084c33c1.png)

19. 什么是分页系统地址映射

    用户程序的地址空间被划分成若干固定大小的区域，称为“页”，相应地，内存空间分成若干个物理块，页和块的大小相等。可将用户程序的任一页放在内存的任一块中，实现了离散分配。

    1. 内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

    2. 一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

    3. 下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。

       [![img](https://github.com/CyC2018/CS-Notes/raw/master/notes/pics/cf4386a1-58c9-4eca-a17f-e12b1e9770eb.png)](https://github.com/CyC2018/CS-Notes/blob/master/notes/pics/cf4386a1-58c9-4eca-a17f-e12b1e9770eb.png)

20. 页面置换算法的目的是什么，有哪些？

    在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

    页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。

    页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）

    ##### 1. 最佳

    > OPT, Optimal replacement algorithm
    >
    > 每个页面都可以用在该页面首次被访问前所要执行的指令数进行标记。最佳页面置换算法只是简单地规定：标记最大的页应该被置换

    所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

    是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

    举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：

    ```
    7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
    ```

    开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。

    ##### 2. 最近最久未使用

    > LRU, Least Recently Used

    虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

    为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

    因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

    ```
    4，7，0，7，1，0，1，2，1，2，6
    ```

    [![img](https://github.com/CyC2018/CS-Notes/raw/master/notes/pics/eb859228-c0f2-4bce-910d-d9f76929352b.png)](https://github.com/CyC2018/CS-Notes/blob/master/notes/pics/eb859228-c0f2-4bce-910d-d9f76929352b.png)

    ##### 3. 最近未使用

    > NRU, Not Recently Used

    每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：

    - R=0，M=0
    - R=0，M=1
    - R=1，M=0
    - R=1，M=1

    当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。

    NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

    ##### 4. 先进先出

    > FIFO, First In First Out

    选择换出的页面是最先进入的页面。

    该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。

    ##### 5. 第二次机会算法

    FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

    当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

    [![img](https://github.com/CyC2018/CS-Notes/raw/master/notes/pics/ecf8ad5d-5403-48b9-b6e7-f2e20ffe8fca.png)](https://github.com/CyC2018/CS-Notes/blob/master/notes/pics/ecf8ad5d-5403-48b9-b6e7-f2e20ffe8fca.png)

    ##### 6. 时钟

    > Clock

    第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

    [![img](https://github.com/CyC2018/CS-Notes/raw/master/notes/pics/5f5ef0b6-98ea-497c-a007-f6c55288eab1.png)](https://github.com/CyC2018/CS-Notes/blob/master/notes/pics/5f5ef0b6-98ea-497c-a007-f6c55288eab1.png)

    

